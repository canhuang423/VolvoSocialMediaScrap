{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c77c1a0f327350f9d39d4704675de5d6b0cfa24513ba433465e87e9d69483b2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "# Tf-Idf and Clustering packages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import string\n",
    "# NTLK functions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize as tok\n",
    "from nltk.stem.snowball import SnowballStemmer # load nltk's SnowballStemmer as variabled 'stemmer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Scraped_Car_Review_volvo.csv\",lineterminator='\\n').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39; We own both the XC90 and S60and have been frustrated with both vehicles.Both have seen more than their fair share of the service department and the lack of concern from Volvo has been discouraging.In two years of the S60, we have had to replace the ignition switches twice. The emergency cable never really engaged properly so it had to be adjusted as well as the sunroof at a cost. A faulty ABS contact reeel and front axle shaft had to be replaced due to recalls. The headlight washer fell off and had to be replaced twice. As if we didn\\x92t feel nickeled and dimed already, we now have to replace the Fire Trap Housing not covered on the warranty. We are very disappointed.&#39;"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df[\"Review\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "isURL = re.compile(r'http[s]?:// (?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', re.VERBOSE | re.IGNORECASE)\n",
    "isRTusername = re.compile(r'^RT+[\\s]+(@[\\w_]+:)',re.VERBOSE | re.IGNORECASE) #r'^RT+[\\s]+(@[\\w_]+:)'\n",
    "isEntity = re.compile(r'@[\\w_]+', re.VERBOSE | re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])) \n",
    "\n",
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer, lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "     \n",
    "        \n",
    "def clean_tweet(row):\n",
    "    row = isURL.sub(\"\",row)\n",
    "    row = isRTusername.sub(\"\",row)\n",
    "    row = isEntity.sub(\"\",row)\n",
    "    return row\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in tok.sent_tokenize(text) for word in tok.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   Review_Date       Author_Name  \\\n0   on 05/16/12 11:58 AM (PDT)     2xvolvoowner    \n1   on 08/29/10 08:28 AM (PDT)          aikiman    \n2   on 05/09/09 11:51 AM (PDT)  Central Florida    \n3   on 11/21/08 18:11 PM (PST)          lordway    \n4   on 09/27/08 22:30 PM (PDT)         Stravage    \n\n                                       Vehicle_Title       Review_Title  \\\n0  2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...     Double trouble   \n1  2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...        First Volvo   \n2  2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...     My first Volvo   \n3  2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...  Relability Stinks   \n4  2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...     1st Impression   \n\n                                              Review  Rating\\r  \\\n0   We own both the XC90 and S60and have been fru...     3.125   \n1   This is my first Volvo, had an Acura and Maxi...     4.625   \n2   I&#39;ve had my Volvo 10 months and love it! I tr...     5.000   \n3   I liked this car a lot when I first bought it...     1.875   \n4   In the past 2 years I have gone from a jeep g...     3.875   \n\n                                        review_clean  \n0   We own both the XC90 and S60and have been fru...  \n1   This is my first Volvo had an Acura and Maxim...  \n2   Ive had my Volvo 10 months and love it I trad...  \n3   I liked this car a lot when I first bought it...  \n4   In the past 2 years I have gone from a jeep g...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review_Date</th>\n      <th>Author_Name</th>\n      <th>Vehicle_Title</th>\n      <th>Review_Title</th>\n      <th>Review</th>\n      <th>Rating\\r</th>\n      <th>review_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>on 05/16/12 11:58 AM (PDT)</td>\n      <td>2xvolvoowner</td>\n      <td>2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...</td>\n      <td>Double trouble</td>\n      <td>We own both the XC90 and S60and have been fru...</td>\n      <td>3.125</td>\n      <td>We own both the XC90 and S60and have been fru...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>on 08/29/10 08:28 AM (PDT)</td>\n      <td>aikiman</td>\n      <td>2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...</td>\n      <td>First Volvo</td>\n      <td>This is my first Volvo, had an Acura and Maxi...</td>\n      <td>4.625</td>\n      <td>This is my first Volvo had an Acura and Maxim...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>on 05/09/09 11:51 AM (PDT)</td>\n      <td>Central Florida</td>\n      <td>2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...</td>\n      <td>My first Volvo</td>\n      <td>I've had my Volvo 10 months and love it! I tr...</td>\n      <td>5.000</td>\n      <td>Ive had my Volvo 10 months and love it I trad...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>on 11/21/08 18:11 PM (PST)</td>\n      <td>lordway</td>\n      <td>2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...</td>\n      <td>Relability Stinks</td>\n      <td>I liked this car a lot when I first bought it...</td>\n      <td>1.875</td>\n      <td>I liked this car a lot when I first bought it...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>on 09/27/08 22:30 PM (PDT)</td>\n      <td>Stravage</td>\n      <td>2008 Volvo S60 Sedan 2.5T 4dr Sedan (2.5L 5cyl...</td>\n      <td>1st Impression</td>\n      <td>In the past 2 years I have gone from a jeep g...</td>\n      <td>3.875</td>\n      <td>In the past 2 years I have gone from a jeep g...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df[\"review_clean\"] = df['Review'].apply(lambda row:clean_tweet(row))\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])  \n",
    "df['review_clean'] = df['review_clean'].str.replace(RE_PUNCTUATION, \"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Topics found via LDA:\n     index   Word 0  Word 1   Word 2    Word 3       Word 4  topic_index\n0  Topic 0      car   volvo    miles  problems       dealer            0\n1  Topic 1      car   volvo    great     drive         like            1\n2  Topic 2  mileage     gas  vehicle     volvo        miles            2\n3  Topic 3   safety  better    volvo  features     interior            3\n4  Topic 4      car   great    volvo     drive  comfortable            4\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        index  Topic0  Topic1  Topic2  Topic3  Topic4  dominant_topic\n0        Doc0    0.75    0.00    0.00    0.23    0.00               0\n1        Doc1    0.48    0.25    0.00    0.00    0.26               0\n2        Doc2    0.01    0.96    0.01    0.01    0.01               1\n3        Doc3    0.51    0.00    0.00    0.00    0.48               0\n4        Doc4    0.00    0.99    0.00    0.00    0.00               1\n...       ...     ...     ...     ...     ...     ...             ...\n4842  Doc4842    0.07    0.92    0.00    0.00    0.00               1\n4843  Doc4843    0.00    0.99    0.00    0.00    0.00               1\n4844  Doc4844    0.00    0.99    0.00    0.00    0.00               1\n4845  Doc4845    0.18    0.62    0.01    0.19    0.01               1\n4846  Doc4846    0.00    0.72    0.00    0.00    0.27               1\n\n[4847 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Topic0</th>\n      <th>Topic1</th>\n      <th>Topic2</th>\n      <th>Topic3</th>\n      <th>Topic4</th>\n      <th>dominant_topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Doc0</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.23</td>\n      <td>0.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doc1</td>\n      <td>0.48</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Doc2</td>\n      <td>0.01</td>\n      <td>0.96</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Doc3</td>\n      <td>0.51</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.48</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Doc4</td>\n      <td>0.00</td>\n      <td>0.99</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4842</th>\n      <td>Doc4842</td>\n      <td>0.07</td>\n      <td>0.92</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4843</th>\n      <td>Doc4843</td>\n      <td>0.00</td>\n      <td>0.99</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4844</th>\n      <td>Doc4844</td>\n      <td>0.00</td>\n      <td>0.99</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4845</th>\n      <td>Doc4845</td>\n      <td>0.18</td>\n      <td>0.62</td>\n      <td>0.01</td>\n      <td>0.19</td>\n      <td>0.01</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4846</th>\n      <td>Doc4846</td>\n      <td>0.00</td>\n      <td>0.72</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.27</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>4847 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "\n",
    "number_topics = 5\n",
    "number_words = 5\n",
    "\n",
    "corpus = df['review_clean'].tolist()\n",
    "    # print(corpus)\n",
    "tf_vectorizer = CountVectorizer(max_df=0.9, min_df=0.00, stop_words=\"english\", tokenizer=tokenize_only) # Use tf (raw term count) features for LDA.\n",
    "tf = tf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Create and fit the LDA model\n",
    "model = LDA(n_components=number_topics, n_jobs=-1)\n",
    "id_topic = model.fit(tf)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "topic_keywords = show_topics(vectorizer=tf_vectorizer, lda_model=model, n_words=number_words)        \n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "\n",
    "df_topic_keywords = df_topic_keywords.reset_index()\n",
    "df_topic_keywords['topic_index'] = df_topic_keywords['index'].str.split(' ', n = 1, expand = True)[[1]].astype('int')\n",
    "print(df_topic_keywords)\n",
    "    \n",
    "############ get the dominat topic for each document in a data frame ###############\n",
    "# Create Document — Topic Matrix\n",
    "lda_output = model.transform(tf)\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(model.n_components)]\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(corpus))]\n",
    "    \n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic   \n",
    "df_document_topic = df_document_topic.reset_index()\n",
    "        \n",
    "df_document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}